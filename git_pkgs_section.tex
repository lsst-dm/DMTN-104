
% do not edit, generated automatically from Github

\newpage
\subsection{lsst-tap-service}\label{lsst-sqre/lsst-tap-service}

IVOA TAP service for LSST


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst-sqre/lsst-tap-service}{https://github.com/lsst-sqre/lsst-tap-service} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{tapsrv}{TAP API} \\
\hline
\end{longtable} }


README.md (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
# LSST TAP Service

This repository contains the LSST TAP service.  It is based on the CADC TAP service
code and uses this as a dependency, and then adds special logic to work with QServ.

## Build

Run ./build.sh

## Deployment

### Docker
After the [Build](#build) step above, a set of containers with the `dev` tag will exist
on your local machine.  Then when you run:

`docker-compose up -d && ./waitForContainersReady.sh && ./checkAvailability.sh`

This should start a local group of containers, wait for them to be ready, and then
check that the availability endpoint returns a 200 and a simple sync query works.
This validates that your local TAP implementation is working.  You can now either
\end{lstlisting}
}


\newpage
\subsection{davt}\label{davt}

WebDAV with substitute user impersonation per-request


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst/davt}{https://github.com/lsst/davt} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{wdavsrv}{WebDAV API} \\
\cdashline{1-2}
{GitHub Teams:} &
 Overlords \\
 & Data Management \\
 & Database \\
\hline
\end{longtable} }


README.md (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
# davt

`davt` is a lua module for nginx to aid with impersonation. Its target use case is for use with 
WebDAV, so that all operations are executed _as the user in the request_. 

For every incoming request, davt enables nginx to switch the OS user (with `setfsuid`) and/or 
group IDs/supplementary group IDs (via `setfsgid`, `setgroups`, `initgroups`) to match the 
authenticated user or specific groups before performing any file opertions.

As davt enables impersonation, a few properties follow:

* The files do NOT need to be owned by an nginx service account user, nor does an ACL need to be 
modified to allow for access to an service group (for filesystems supporting ACLs). This allows 
you to transperently operate the service over existing directories.

* Ownership when creating files is preserved for the files in question. This ensures that files 
created for the user via WebDAV are also readable when the user is in a shell, for example.

## Requirements
davt requires ljsyscall. It also used the ffi library from LuaJIT.
\end{lstlisting}
}


\newpage
\subsection{nublado}\label{lsst-sqre/nublado}

JupyterLab + JupyterHub + k8s deployment used by LSST for its Science
Platform


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst-sqre/nublado}{https://github.com/lsst-sqre/nublado} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{nblsrv}{LSP Nublado} \\
\hline
\end{longtable} }


README.md (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
# LSST Science Platform Notebook Aspect

## Do Not Use This

If what you want to do is simply deploy a Jupyter setup under Kubernetes
you're much better off
using
[Zero to JupyterHub](https://zero-to-jupyterhub.readthedocs.io/en/latest/),
which is an excellent general tutorial for setting up
JupyterHub in a Kubernetes environment.

This cluster is much more specifically tailored to the needs
of [LSST](https://lsst.org).  If you want an example of how to set up
persistent storage for your users, how to ship logs to a remote ELK
stack, a worked example of how to subclass a spawner, or how to use an
image-spawner options menu, you may find it useful.

## Overview

The LSST Science Platform Notebook Aspect is a JupyterHub + JupyterLab
\end{lstlisting}
}


\newpage
\subsection{dbb\_gwclient}\label{lsst-dm/dbb_gwclient}

Prototype code to save raw files to Data Backbone Gateway


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst-dm/dbb_gwclient}{https://github.com/lsst-dm/dbb\_gwclient} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{dbbmd}{DBB Ingest/ Metadata Management SW} \\
\hline
\end{longtable} }


README.md (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
# dbb_gwclient
Prototype code to save raw files to Data Backbone Gateway.

This is a Python 3 only package (we assume Python 3.6 or higher).
\end{lstlisting}
}


\newpage
\subsection{dbb\_gateway}\label{lsst-dm/dbb_gateway}

Prototype code that ingests into the Data Backbone raw files delivered
by the dbb\_gwclient to the DBB gateway


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst-dm/dbb_gateway}{https://github.com/lsst-dm/dbb\_gateway} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{dbbmd}{DBB Ingest/ Metadata Management SW} \\
\hline
\end{longtable} }

\begin{longtable}{rl}
\multicolumn{2}{c}{EUPS dependencies} \\ \hline
\textbf{name} & \textbf{description} \\ \hline
{\footnotesize pyfits } & \\ \hline
\end{longtable}

README.md (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
# dbb_gateway
Prototype code that ingests into the Data Backbone raw files delivered by the dbb_gwclient to the DBB gateway
\end{lstlisting}
}


\newpage
\subsection{scipipe\_conda\_env}\label{scipipe_conda_env}

Conda environment for LSST Science Pipelines


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst/scipipe_conda_env}{https://github.com/lsst/scipipe\_conda\_env} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{splce}{SciencePipelines Conda Env.} \\
\cdashline{1-2}
{GitHub Teams:} &
 Data Management \\
 & DM Auxilliaries \\
\hline
\end{longtable} }


README.md (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
# Conda Environment for Science Pipelines

This repository contains the definition of the Conda environment used by the LSST Science Pipelines.

## Contents

Files in the `etc` directory are named following the pattern:

```
conda3_<filetype>-<platform>-64.yml
```

Where `<filetype>` is one of:

- `bleed`, indicating the names of packages on which the Science Pipelines directly depend, or
- `packages`, indicating a specific versioned set of those packages, and packages upon which they depend, which can be directly instantiated as a Conda environment.

And `<platform>` is one of:

- `linux`, indicating that this file has been tested on CentOS (our reference platform), and, by extension, is appropriate for use on a Linux systems;
\end{lstlisting}
}


\newpage
\subsection{dax\_imgserv}\label{dax_imgserv}

Web Interface for LSST Image Services


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst/dax_imgserv}{https://github.com/lsst/dax\_imgserv} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{daximg}{Image/ Cutout Server} \\
\cdashline{1-2}
{GitHub Teams:} &
 Overlords \\
 & Data Management \\
 & Database \\
\hline
\end{longtable} }

\begin{longtable}{rl}
\multicolumn{2}{c}{EUPS dependencies} \\ \hline
\textbf{name} & \textbf{description} \\ \hline
{\footnotesize afw } & \\ \hline
{\footnotesize base } & \\ \hline
{\footnotesize boost } & \\ \hline
{\footnotesize daf\_base } & \\ \hline
{\footnotesize daf\_persistence } & \\ \hline
{\footnotesize doxygen } & \\ \hline
{\footnotesize log } & \\ \hline
{\footnotesize obs\_sdss } & \\ \hline
{\footnotesize scons } & \\ \hline
{\footnotesize sconsUtils } & \\ \hline
{\footnotesize skymap } & \\ \hline
{\footnotesize sqlalchemy } & \\ \hline
\end{longtable}

README.txt (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
# Useful link:
http://blog.miguelgrinberg.com/post/designing-a-restful-api-with-python-and-flask

# To install flask:
sudo aptitude install python-flask

# To run some quick tests:

  # run the server
  python bin/imageServer.py

  # and fetch the urls:
  http://localhost:5000/api/image/soda/availability
  http://localhost:5000/api/image/soda/capabilities
  http://localhost:5000/api/image/soda/examples
  http://localhost:5000/api/image/soda/sync?ID=DC_W13_Stripe82.calexp.r&POS=CIRCLE+37.644598+0.104625+100
  http://localhost:5000/api/image/soda/sync?ID=DC_W13_Stripe82.calexp.r&POS=RANGE+37.616820222+37.67235778+0.07684722222+0.132402777
  http://localhost:5000/api/image/soda/sync?ID=DC_W13_Stripe82.calexp.r&POS=POLYGON+37.6580803+0.0897081+37.6580803+0.1217858+37.6186104+0.1006648
  http://localhost:5000/api/image/soda/sync?ID=DC_W13_Stripe82.calexp.r&POS=BRECT+37.644598+0.104625+100+100+pixel
\end{lstlisting}
}


\newpage
\subsection{dax\_webserv}\label{dax_webserv}

Web Interface for LSST Data Access Services


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst/dax_webserv}{https://github.com/lsst/dax\_webserv} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{lspweb}{LSP Web API SW (obsolete product)} \\
\cdashline{1-2}
{GitHub Teams:} &
 Overlords \\
 & Data Management \\
 & Database \\
\hline
\end{longtable} }

\begin{longtable}{rl}
\multicolumn{2}{c}{EUPS dependencies} \\ \hline
\textbf{name} & \textbf{description} \\ \hline
{\footnotesize db } & \\ \hline
{\footnotesize flask } & \\ \hline
{\footnotesize dax\_dbserv } & \\ \hline
{\footnotesize dax\_imgserv } & \\ \hline
{\footnotesize dax\_metaserv } & \\ \hline
{\footnotesize python\_mysqlclient } & \\ \hline
\end{longtable}

README.txt (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
# Useful link:
http://blog.miguelgrinberg.com/post/designing-a-restful-api-with-python-and-flask
http://pycoder.net/bospy/presentation.html

# To install flask:
sudo aptitude install python-flask


# An example Tap query to dbserv (if running locally)
  curl -d 'query=SELECT+ra,decl,filterName+FROM+DC_W13_Stripe82.Science_Ccd_Exposure+WHERE+scienceCcdExposureId=125230127' http://localhost:5000/db/v0/sync
\end{lstlisting}
}


\newpage
\subsection{jupyterhubutils}\label{lsst-sqre/jupyterhubutils}

Utilities for LSST LSP notebook environment (Hub/spawner side)


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst-sqre/jupyterhubutils}{https://github.com/lsst-sqre/jupyterhubutils} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{nbsw}{LSP Notebook Software} \\
\hline
\end{longtable} }


README.md (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
# Utilities for LSST LSP notebook environment (Hub/spawner side)
\end{lstlisting}
}


\newpage
\subsection{jupyterlabutils}\label{lsst-sqre/jupyterlabutils}

Utilities for JupyterLab containers in LSST Science Platform environment


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst-sqre/jupyterlabutils}{https://github.com/lsst-sqre/jupyterlabutils} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{nbsw}{LSP Notebook Software} \\
\hline
\end{longtable} }


README.md (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
# Utilities for LSST LSP Science Platform notebook aspect (user pod side)
\end{lstlisting}
}


\newpage
\subsection{suit-onlinehelp}\label{suit-onlinehelp}



{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst/suit-onlinehelp}{https://github.com/lsst/suit-onlinehelp} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{prtloh}{LSP Portal Online Help} \\
\hline
\end{longtable} }


README.md (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
# suit-onlinehelp

Prerequisites
-------------
    - gradle v2.2+
    - clone onlinehelp repository and its dependent repository
        - git clone https://github.com/lsst/suit-onlinehelp
        - git clone https://github.com/Caltech-IPAC/firefly


Build and Install Individually
------------------------------
- cd suit-onlinehelp
- gradle :<project_name>:build      // build only
    - creates an archive of html and supporting files to be install to a webserver
    - the file is placed in ./build/libs/

- gradle :<project_name>:install    // build and install.
    - crates and install online help files
    - HTML_DOC_ROOT environment variable is required to locate the path to the webserver's document root.
\end{lstlisting}
}


\newpage
\subsection{suit}\label{suit}



{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst/suit}{https://github.com/lsst/suit} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{prtlsw}{LSP Portal Software} \\
\cdashline{1-2}
{GitHub Teams:} &
 Data Management \\
\hline
\end{longtable} }


README.md (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
# SUIT 


## Description
The SUIT (Science User Interface and Tools) repository contains applications built on the Firefly Toolkit.
It is meant to be used with [Firefly](https://github.com/Caltech-IPAC/firefly).

The principal current application is "suit", otherwise known as the Portal Aspect application, which
contains both the Portal search screens and visualization capabilities, and the "slate" endpoint that
is used for Python-based image and table visualizations.


## Build Instuctions
 
 - Install [JDK 8](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)   
   
 - Install [Gradle 4.x](https://gradle.org/install/)
 
 - Install [Node.js 8.x](https://nodejs.org/en/download/)
 
\end{lstlisting}
}


\newpage
\subsection{alert\_stream}\label{lsst-dm/alert_stream}

Mock alert stream distribution system using Kafka producers and
consumers.


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst-dm/alert_stream}{https://github.com/lsst-dm/alert\_stream} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{alrtdstr}{Alert Distribution SW} \\
\hline
\end{longtable} }


README.rst (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
############
alert_stream
############

This package provides a demonstration of the LSST Alert Distribution Service.
The Alert Distribution Service provides a mechanism for rapidly disseminating and filtering notifications of transient and variable sources observed by LSST.
The service is described in detail in `DMTN-093`_.
This repository provides instructions, code and sample data for creating, filtering, and consuming alert streams following the conventions we expect to adopt for LSST.
It should be used in conjunction with the `lsst-dm/sample-avro-alert`_ repository, which provides details of, and code for working with, LSST alert packets.

.. _DMTN-093: https://dmtn-093.lsst.io/
.. _lsst-dm/sample-avro-alert: https://github.com/lsst-dm/sample-avro-alert

Prerequisites
=============

- Cloning this repository requires `Git LFS`_ (Large File Storage) support.
  Refer to the `DM Developer Guide`_ for more information.
- `Docker`_ and `Docker Compose`_ are required to create and manage the services within this repository, including running all of the examples below.

\end{lstlisting}
}


\newpage
\subsection{HeaderService}\label{lsst-dm/headerservice}

LSST Meta-data aggregator for FITS header service


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst-dm/HeaderService}{https://github.com/lsst-dm/HeaderService} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{header}{Header Service SW} \\
\hline
\end{longtable} }

\begin{longtable}{rl}
\multicolumn{2}{c}{EUPS dependencies} \\ \hline
\textbf{name} & \textbf{description} \\ \hline
{\footnotesize fitsio } & \\ \hline
\end{longtable}

README.md (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
# HeaderService

Development for LSST Meta-data FITS header service

Description
-----------

This is the development for the LSST Meta-data FITS header client. It
uses a set of FITS header library templates and DDS/SAL Python-based
communication layer to populate meta-data and command the header
client to write header files.

Requirements
------------
+ numpy
+ astropy
+ fitsio (https://github.com/esheldon/fitsio)
+ salobj
+ OpenSplice compiled binaries for centOS7
+ A CentOS7 VM or docker container
\end{lstlisting}
}


\newpage
\subsection{ctrl\_iip}\label{ctrl_iip}

Image ingest and processing


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst/ctrl_iip}{https://github.com/lsst/ctrl\_iip} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{iip}{Image Ingest and Processing} \\
\cdashline{1-2}
{GitHub Teams:} &
 Data Management \\
\hline
\end{longtable} }


README.md (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
# ctrl_iip
Image ingest and processing

environment variables:

Set CTRL_IIP_DIR to the root of this repository. (this will be set automatically
when this is integrated with the DM system)

Set PYTHONPATH to include $CTRL_IPP_DIR/python



Note about configuration files:

Configuration files are loaded from $CTRL_IIP_DIR/etc/config by default

If the environment variable IIP_CONFIG_DIR is set, it will look in 
this directory for configuration files.
\end{lstlisting}
}


\newpage
\subsection{ctrl\_oods}\label{lsst-dm/ctrl_oods}

Observatory Operations Data Service


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst-dm/ctrl_oods}{https://github.com/lsst-dm/ctrl\_oods} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{oods}{Observatory Operations Data Service SW} \\
\hline
\end{longtable} }

\begin{longtable}{rl}
\multicolumn{2}{c}{EUPS dependencies} \\ \hline
\textbf{name} & \textbf{description} \\ \hline
{\footnotesize base } & \\ \hline
{\footnotesize utils } & \\ \hline
{\footnotesize sconsUtils } & \\ \hline
{\footnotesize obs\_lsst } & \\ \hline
\end{longtable}

README.rst (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
#########
ctrl_oods
#########

``ctrl_oods`` is an `LDF Prompt Enclave Software`_ package.

.. Add a brief (few sentence) description of what this package provides.

The Observatory Operations Data Service watches for files in one or more directories, and then ingests them into an LSST Butler repository.   
Files are expired from the repository at specified intervals.
\end{lstlisting}
}


\newpage
\subsection{squash}\label{lsst-sqre/squash}

SQuaSH web interface


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst-sqre/squash}{https://github.com/lsst-sqre/squash} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{qcsw}{Quality Control SW} \\
\hline
\end{longtable} }


README.md (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
# squash

`squash` is the web frontend to embed the bokeh apps and navigate through them. You can learn more about SQuaSH at [SQR-009](https://sqr-009.lsst.io).

[![Build Status](https://travis-ci.org/lsst-sqre/squash.svg?branch=master)](https://travis-ci.org/lsst-sqre/squash)

## Requirements

The `squash` web frontend requires the [squash-restful-api](https://github.com/lsst-sqre/squash-restful-api) and [squash-bokeh](https://github.com/lsst-sqre/squash-bokeh) microservices, and the TLS certificats that are installed by the
[`squash-deployment`](https://github.com/lsst-sqre/squash-deployment).

## Kubernetes deployment

You can provision a Kubernetes cluster in GKE, clone this repo and deploy the `squash` microservice using:

```
cd squash
TAG=latest make service deployment
```

\end{lstlisting}
}


\newpage
\subsection{ap\_pipe}\label{ap_pipe}

LSST Data Management Alert Production Pipeline


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst/ap_pipe}{https://github.com/lsst/ap\_pipe} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{apprmpt}{Alert Production} \\
\cdashline{1-2}
{GitHub Teams:} &
 Overlords \\
 & Data Management \\
\hline
\end{longtable} }

\begin{longtable}{rl}
\multicolumn{2}{c}{EUPS dependencies} \\ \hline
\textbf{name} & \textbf{description} \\ \hline
{\footnotesize utils } & \\ \hline
{\footnotesize pex\_config } & \\ \hline
{\footnotesize pipe\_base } & \\ \hline
{\footnotesize pipe\_tasks } & \\ \hline
{\footnotesize ap\_association } & \\ \hline
\end{longtable}

README.md (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
# ap_pipe

This package contains the LSST Data Management Alert Production Pipeline.

For up-to-date documentation, including a tutorial, see the `doc` directory.

ap_pipe processes raw images that have been ingested into a Butler repository
with corresponding calibration products and templates. It produces calexps,
difference images and source catalogs, and an association database.

The user must specify the main repository with ingested images (and the
location of the calibration products and templates if they reside elsewhere),
the name of the association database (may be either created from scratch or
connected to for continued associating), and a Butler data ID.
\end{lstlisting}
}


\newpage
\subsection{cp\_pipe}\label{cp_pipe}

Calibration-products production pipeline


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst/cp_pipe}{https://github.com/lsst/cp\_pipe} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{dmcal}{Calibration Software} \\
\cdashline{1-2}
{GitHub Teams:} &
 Overlords \\
 & Data Management \\
 & DMLT \\
\hline
\end{longtable} }

\begin{longtable}{rl}
\multicolumn{2}{c}{EUPS dependencies} \\ \hline
\textbf{name} & \textbf{description} \\ \hline
{\footnotesize pex\_config } & \\ \hline
{\footnotesize pipe\_base } & \\ \hline
{\footnotesize log } & \\ \hline
{\footnotesize ip\_isr } & \\ \hline
{\footnotesize afw } & \\ \hline
{\footnotesize meas\_algorithms } & \\ \hline
\end{longtable}

README.rst (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
#######################################
Calibration Products Production Package
#######################################

Code to produce calibration products, required to perform ISR and other calibration tasks.
\end{lstlisting}
}


\newpage
\subsection{mops\_daymops}\label{mops_daymops}



{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst/mops_daymops}{https://github.com/lsst/mops\_daymops} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{mops}{MOPS and Forced Photometry} \\
\cdashline{1-2}
{GitHub Teams:} &
 Overlords \\
 & Data Management \\
\hline
\end{longtable} }

\begin{longtable}{rl}
\multicolumn{2}{c}{EUPS dependencies} \\ \hline
\textbf{name} & \textbf{description} \\ \hline
{\footnotesize "scons" } & \\ \hline
{\footnotesize "swig" } & \\ \hline
{\footnotesize "gsl" } & \\ \hline
{\footnotesize "daf\_base" } & \\ \hline
{\footnotesize pex\_exceptions } & \\ \hline
{\footnotesize "slalib" } & \\ \hline
{\footnotesize "eigen" >=3.0.0 } & \\ \hline
{\footnotesize "mysqlpython" } & \\ \hline
{\footnotesize "numpy" } & \\ \hline
\end{longtable}

README.quickstart.txt (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
Here's a greatly simplified guide to running MOPS at the moment, which
will run findTracklets, collapseTracklets linkTracklets for you.

I was using Bash when I came up with these, you may need to change a
few things if you're using *csh.

# set up your environment
setlsst
setup mysqlpython
setup mops_daymops
export MOPS_HACKS=$MOPS_DAYMOPS_DIR/tests/experimentScripts/

# get data
mkdir myMopsRun
cd myMopsRun
wget --user=USER --password=PASSWORD dias_pt1_nodeep.short.astromErr


# populate the DB for later. I assume you have the OpSim DB already.
echo "CREATE DATABASE myMops; USE myMops; `cat fullerDiaSource.sql`;" | mysql
\end{lstlisting}
}
README.txt (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
Jmyers Oct 22

Updated thoroughly to describe how I'm currently doing things.

The following is a set of instructions for running
find/collapse/linkTracklets on some diaSources. 

In the future these scripts (or more likely, better versions of
all of this) will be modified so that pipelines can run each
stage of find/collapse/linkTracklets on particular sets of data.

All the scripts should be in the same directory as this readme file.



INSTALLING/BUILDING C++ FIND/LINKTRACKLETS (etc.)
---------------------------------------

Build the C++ tools using instructions online at http://dev.lsstcorp.org/trac/wiki/MOPS/Installing_MOPS

\end{lstlisting}
}


\newpage
\subsection{lsst\_distrib}\label{lsst_distrib}



{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst/lsst_distrib}{https://github.com/lsst/lsst\_distrib} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{spdist}{Science Pipelines Distribution} \\
\cdashline{1-2}
{GitHub Teams:} &
 Overlords \\
 & Data Management \\
\hline
\end{longtable} }

\begin{longtable}{rl}
\multicolumn{2}{c}{EUPS dependencies} \\ \hline
\textbf{name} & \textbf{description} \\ \hline
{\footnotesize lsst\_apps } & \\ \hline
{\footnotesize ctrl\_execute } & \\ \hline
{\footnotesize ctrl\_mpexec } & \\ \hline
{\footnotesize ctrl\_platform\_lsstvc } & \\ \hline
{\footnotesize jointcal } & \\ \hline
{\footnotesize verify } & \\ \hline
{\footnotesize ap\_verify } & \\ \hline
{\footnotesize display\_firefly } & \\ \hline
{\footnotesize display\_matplotlib } & \\ \hline
{\footnotesize cp\_pipe } & \\ \hline
{\footnotesize validate\_drp } & \\ \hline
{\footnotesize fgcmcal } & \\ \hline
\end{longtable}



\newpage
\subsection{albuquery}\label{albuquery}

DAX Query Services in Kotlin


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst/albuquery}{https://github.com/lsst/albuquery} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{adql}{ADQL Translator} \\
\hline
\end{longtable} }


README.rst (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
#########
albuquery
#########

``albuquery`` will implement a TAP database query service for the Web APIs Aspect of the LSST Science Platform (a.k.a. Data Access Services/DAX).
\end{lstlisting}
}


\newpage
\subsection{daf\_butler}\label{daf_butler}

Prototype for data access framework described in \citeds{DMTN-056}

{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst/daf_butler}{https://github.com/lsst/daf\_butler} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{butler}{Data Butler} \\
\cdashline{1-2}
{GitHub Teams:} &
 Overlords \\
 & Data Management \\
 & Database \\
\hline
\end{longtable} }

\begin{longtable}{rl}
\multicolumn{2}{c}{EUPS dependencies} \\ \hline
\textbf{name} & \textbf{description} \\ \hline
{\footnotesize astropy } & \\ \hline
{\footnotesize sphgeom } & \\ \hline
{\footnotesize sqlalchemy } & \\ \hline
{\footnotesize numpy } & \\ \hline
{\footnotesize scons } & \\ \hline
{\footnotesize sconsUtils } & \\ \hline
{\footnotesize utils } & \\ \hline
{\footnotesize astro\_metadata\_translator } & \\ \hline
{\footnotesize geom } & \\ \hline
{\footnotesize afw } & \\ \hline
\end{longtable}

README.md (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
# daf_butler

LSST Data Access framework described in [DMTN-056](https://dmtn-056.lsst.io).

This is a **Python 3 only** package (we assume Python 3.6 or higher).
\end{lstlisting}
}


\newpage
\subsection{qserv}\label{qserv}

LSST Query Services


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst/qserv}{https://github.com/lsst/qserv} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{qserv}{Distributed Database} \\
\cdashline{1-2}
{GitHub Teams:} &
 Overlords \\
 & Data Management \\
\hline
\end{longtable} }

\begin{longtable}{rl}
\multicolumn{2}{c}{EUPS dependencies} \\ \hline
\textbf{name} & \textbf{description} \\ \hline
{\footnotesize antlr4 } & \\ \hline
{\footnotesize boost } & \\ \hline
{\footnotesize db } & \\ \hline
{\footnotesize doxygen } & \\ \hline
{\footnotesize flask } & \\ \hline
{\footnotesize jemalloc } & \\ \hline
{\footnotesize libcurl } & \\ \hline
{\footnotesize log } & \\ \hline
{\footnotesize log4cxx } & \\ \hline
{\footnotesize lua } & \\ \hline
{\footnotesize mariadb } & \\ \hline
{\footnotesize mysqlproxy } & \\ \hline
{\footnotesize json\_nlohmann } & \\ \hline
{\footnotesize python\_mysqlclient } & \\ \hline
{\footnotesize partition } & \\ \hline
{\footnotesize protobuf } & \\ \hline
{\footnotesize pybind11 } & \\ \hline
{\footnotesize python } & \\ \hline
{\footnotesize redis\_plus\_plus } & \\ \hline
{\footnotesize requests } & \\ \hline
{\footnotesize scisql } & \\ \hline
{\footnotesize scons } & \\ \hline
{\footnotesize sphgeom } & \\ \hline
{\footnotesize sqlalchemy } & \\ \hline
{\footnotesize xrootd } & \\ \hline
\end{longtable}

README.md (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
# Qserv: petascale distributed database

## Master branch status

Continuous integration server launches Qserv build and also multi-node integration tests:

[![Build Status](https://travis-ci.org/lsst/qserv.svg?branch=master)](https://travis-ci.org/lsst/qserv)

[![Code Climate](https://codeclimate.com/github/lsst/qserv/badges/gpa.svg)](https://codeclimate.com/github/lsst/qserv)

[![Issue Count](https://codeclimate.com/github/lsst/qserv/badges/issue_count.svg)](https://codeclimate.com/github/lsst/qserv)

## Documentation

### Current release


See http://slac.stanford.edu/exp/lsst/qserv/

### Development version
\end{lstlisting}
}


\newpage
\subsection{lsst\_apps}\label{lsst_apps}



{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst/lsst_apps}{https://github.com/lsst/lsst\_apps} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{scipipe}{Science Pipelines Libraries} \\
\cdashline{1-2}
{GitHub Teams:} &
 Overlords \\
 & Data Management \\
\hline
\end{longtable} }

\begin{longtable}{rl}
\multicolumn{2}{c}{EUPS dependencies} \\ \hline
\textbf{name} & \textbf{description} \\ \hline
{\footnotesize meas\_deblender } & \\ \hline
{\footnotesize meas\_modelfit } & \\ \hline
{\footnotesize pipe\_tasks } & \\ \hline
{\footnotesize ap\_pipe } & \\ \hline
{\footnotesize obs\_lsstSim } & \\ \hline
{\footnotesize obs\_sdss } & \\ \hline
{\footnotesize obs\_test } & \\ \hline
{\footnotesize meas\_extensions\_simpleShape } & \\ \hline
\end{longtable}



\newpage
\subsection{pipe\_supertask}\label{pipe_supertask}

Super Task implementation


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst/pipe_supertask}{https://github.com/lsst/pipe\_supertask} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{txf}{Task Framework} \\
\hline
\end{longtable} }

\begin{longtable}{rl}
\multicolumn{2}{c}{EUPS dependencies} \\ \hline
\textbf{name} & \textbf{description} \\ \hline
{\footnotesize daf\_butler } & \\ \hline
{\footnotesize log } & \\ \hline
{\footnotesize pex\_config } & \\ \hline
{\footnotesize pipe\_base } & \\ \hline
\end{longtable}

README.md (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
# pipe_supertask
Super Task implementation
\end{lstlisting}
}


\newpage
\subsection{astrometry\_net\_data}\label{astrometry_net_data}



{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst/astrometry_net_data}{https://github.com/lsst/astrometry\_net\_data} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{and}{Astrometry.net Data} \\
\cdashline{1-2}
{GitHub Teams:} &
 Overlords \\
 & Data Management \\
 & DM Externals \\
\hline
\end{longtable} }

\begin{longtable}{rl}
\multicolumn{2}{c}{EUPS dependencies} \\ \hline
\textbf{name} & \textbf{description} \\ \hline
{\footnotesize sconsUtils } & \\ \hline
\end{longtable}



\newpage
\subsection{sqre-codekit}\label{lsst-sqre/sqre-codekit}

LSST DM SQuaRE misc. code management tools


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst-sqre/sqre-codekit}{https://github.com/lsst-sqre/sqre-codekit} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{cdkt}{codekit} \\
\hline
\end{longtable} }


README.md (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
[![Build Status](https://travis-ci.org/lsst-sqre/sqre-codekit.svg?branch=master)](https://travis-ci.org/lsst-sqre/sqre-codekit)

# sqre-codekit

LSST DM SQuaRE misc. code management tools

## Installation

sqre-codekit runs on Python 3.6 or newer. You can install it with

```bash
pip install sqre-codekit
```

## Available commands

- `github-auth`: Generate a GitHub authentication token.
- `github-decimate-org`: Delete repos and/or teams from a GitHub organization.
- `github-fork-org`: Fork repositories from one GitHub organization to another.
- `github-get-ratelimit`: Display the current github ReST API request ratelimit.
\end{lstlisting}
}


\newpage
\subsection{jenkins-dm-jobs}\label{lsst-dm/jenkins-dm-jobs}

Jenkins jobs and pipeline scripts for LSST DM


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst-dm/jenkins-dm-jobs}{https://github.com/lsst-dm/jenkins-dm-jobs} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{jscr}{jenkins scripting} \\
\hline
\end{longtable} }


README.md (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
jenkins-dm-jobs
===

[![Build Status](https://travis-ci.org/lsst-dm/jenkins-dm-jobs.png)](https://travis-ci.org/lsst-dm/jenkins-dm-jobs)
\end{lstlisting}
}


\newpage
\subsection{lsst\_build}\label{lsst_build}



{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst/lsst_build}{https://github.com/lsst/lsst\_build} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{lbld}{lsst\_build} \\
\cdashline{1-2}
{GitHub Teams:} &
 Overlords \\
 & Data Management \\
 & DM Auxilliaries \\
\hline
\end{longtable} }


README.md (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
lsst-build, a builder and continuous integration tool for LSST
==============================================================

[![Build Status](https://travis-ci.org/lsst/lsst_build.svg?branch=master)](https://travis-ci.org/lsst/lsst_build)

Provides the following capabilities:

* Given one or more top-level packages, intelligently clone their git
  repositories and check out the requested branches into a build directory:

  ```bash
  lsst-build prepare
     [--repository-pattern=format_pattern_for_repo_URLs]
     [--exclusion-map=exclusions.txt]
     [--version-git-repo=versiondbdir]
     [--ref=branch1 [--ref=branch2 [...]]]
     <builddir> <product1> [product2 [product3 [...]]]
  ```

  Run `lsst-build prepare -h` to see the full list of options.
\end{lstlisting}
}


\newpage
\subsection{lsstsw}\label{lsstsw}

loadLSST


{\footnotesize
\begin{longtable}{rl}
\hline
Open it in GitHUb: & \href{https://github.com/lsst/lsstsw}{https://github.com/lsst/lsstsw} \\ \cdashline{1-2}
Top Level Component: & \hyperlink{lsstsw}{lsstsw} \\
\cdashline{1-2}
{GitHub Teams:} &
 Overlords \\
 & Data Management \\
\hline
\end{longtable} }


README.md (First 20 lines only)
{\scriptsize
\begin{lstlisting}[breaklines]
LSST Distribution Server Account
================================

[![Build Status](https://travis-ci.org/lsst/lsstsw.png)](https://travis-ci.org/lsst/lsstsw)

**`repos.yaml` has been migrated to [`lsst/repos`](https://github.com/lsst/repos).**

For a guide to using `lsstsw`, see:

http://developer.lsst.io/en/latest/build-ci/lsstsw.html

*Note: this directory is git managed.*

Structure
---------

| path       | description                                                    |
| :----------|:---------------------------------------------------------------|
| miniconda  | Anaconda Python distribution                                   |
| bin        | software distribution binaries (rebuild, publish)              |
\end{lstlisting}
}



